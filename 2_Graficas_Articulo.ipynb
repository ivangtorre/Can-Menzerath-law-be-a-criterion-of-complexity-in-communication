{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from scipy.optimize import curve_fit\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_language(lang):\n",
    "    if lang == \"en\": return \"English\"\n",
    "    elif lang == \"fr\": return \"French\"\n",
    "    elif lang == \"fi\": return \"Finish\"\n",
    "    elif lang == \"de\": return \"German\"\n",
    "    elif lang == \"it\": return \"Italian\"\n",
    "    elif lang == \"nl\": return \"Dutch\"\n",
    "    elif lang == \"es\": return \"Spanish\"\n",
    "    elif lang == \"pt\": return \"Portuguese\"\n",
    "    elif lang == \"hu\": return \"Hungarian\"\n",
    "    elif lang == \"sv\": return \"Swedish\"\n",
    "    elif lang == \"eo\": return \"Esperanto\"\n",
    "    elif lang == \"la\": return \"Latin\"\n",
    "    elif lang == \"da\": return \"Danish\"\n",
    "    elif lang == \"tl\": return \"Tagalog\"\n",
    "    elif lang == \"ca\": return \"Catalan\"\n",
    "    elif lang == \"pl\": return \"Polish\"\n",
    "    elif lang == \"no\": return \"Norwegian\"\n",
    "    elif lang == \"cs\": return \"Czech\"\n",
    "    elif lang == \"cy\": return \"Welsh\"\n",
    "    elif lang == \"is\": return \"Icelandic\"\n",
    "    elif lang == \"af\": return \"Afrikaans\"\n",
    "\n",
    "\n",
    "def func_powerlawexp(x, alfa, beta, gamma):\n",
    "        return alfa * x**(beta) * np.exp(-gamma*x)\n",
    "    \n",
    "def latex_float(f):\n",
    "    float_str = \"{:.1e}\".format(f)\n",
    "    if \"e\" in float_str:\n",
    "        base, exponent = float_str.split(\"e\")\n",
    "        return \"${0} \\\\cdot 10^{{{1}}}$\".format(base, int(exponent))\n",
    "    else:\n",
    "        return float_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listaidiomas = [\"en\", \"fr\", \"fi\", \"de\", \"it\", \"nl\", \"es\", \"pt\", \"hu\", \"sv\", \"eo\", \"la\", \"da\",\n",
    "                 \"tl\", \"ca\", \"pl\", \"no\", \"cs\", \"cy\", \"is\", \"af\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Spearman Correlations without first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2save = []\n",
    "for lang in listaidiomas:\n",
    "    outputname = \"MAL_FullFrom2_Spearman\" + lang\n",
    "            \n",
    "    result_path = \"results/\" + lang + \"/menzerath_altmann_\" + lang + \".csv\"\n",
    "    df = pd.read_csv(result_path, index_col=0, header=[0,1]).mean_syllabe_length\n",
    "    df = df[df[\"count\"]>25]\n",
    "#     df = df[df.index.values<13] # At least some values FILTER\n",
    "    df = df[df.index.values>1]\n",
    "    correlationdata, pvaluedata = stats.spearmanr(df[\"mean\"].index, df[\"mean\"].values)\n",
    "\n",
    "    BHMM_path = \"results/\" + lang + \"/HMM_menzerath_\" + lang + \".csv\"\n",
    "    BHMM = pd.read_csv(BHMM_path, index_col=1)[\"value\"]\n",
    "    \n",
    "    correlationBHMM, pvalueBHMM = stats.spearmanr(BHMM.index, BHMM.values)\n",
    "\n",
    "    \n",
    "    list2save.append([return_language(lang) + \" & \" + str(round(correlationdata,2)) + \" & \" + str(round(pvaluedata,2)) +\n",
    "                      \" & \" + str(round(correlationBHMM, 2)) + \" & \" + str(round(pvalueBHMM,2)) + \"\\\\\" + \"\\\\\"])\n",
    "\n",
    "pd.DataFrame(list2save, columns=['Language & Data corr & Data p & BHMM corr & BHMM p']).to_csv(\"results/Figures_Article/FullCorpusFrom2/Correlations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Spearman Correlationsfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2save = []\n",
    "\n",
    "\n",
    "for lang in listaidiomas:\n",
    "    outputname = \"MAL_FullFrom2_Spearman\" + lang\n",
    "            \n",
    "    result_path = \"results/\" + lang + \"/menzerath_altmann_\" + lang + \".csv\"\n",
    "    df = pd.read_csv(result_path, index_col=0, header=[0,1]).mean_syllabe_length\n",
    "    df = df[df[\"count\"]>25]\n",
    "#     df = df[df.index.values<13] # At least some values FILTER\n",
    "#     df = df[df.index.values>1]\n",
    "    correlationdata, pvaluedata = stats.spearmanr(df[\"mean\"].index, df[\"mean\"].values)\n",
    "\n",
    "    BHMM_path = \"results/\" + lang + \"/HMM_menzerath_\" + lang + \".csv\"\n",
    "    BHMM = pd.read_csv(BHMM_path, index_col=1)[\"value\"]\n",
    "    \n",
    "    correlationBHMM, pvalueBHMM = stats.spearmanr(BHMM.index, BHMM.values)\n",
    "\n",
    "    \n",
    "    list2save.append([return_language(lang) + \" & \" + str(round(correlationdata,2)) + \" & \" + str(round(pvaluedata,2)) +\n",
    "                      \" & \" + str(round(correlationBHMM, 2)) + \" & \" + str(round(pvalueBHMM,2)) + \"\\\\\" + \"\\\\\"])\n",
    "\n",
    "pd.DataFrame(list2save, columns=['Language & Data corr & Data p & BHMM corr & BHMM p']).to_csv(\"results/Figures_Article/FullCorpusFrom1/Correlations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_Menzerath(f, ax, outputname, flag, lang, dataframe, HMM, output_dir, from1=None):\n",
    "    if flag%5==0: color = \"blue\"\n",
    "    if flag%5==1: color = \"red\"\n",
    "    if flag%5==2: color = \"green\"\n",
    "    if flag%5==3: color = \"orange\"\n",
    "    if flag%5==4: color = \"purple\"\n",
    "    if flag==21: color = \"gray\"\n",
    "        \n",
    "    language = return_language(lang)\n",
    "    syllables = dataframe.index.values\n",
    "    phonemes = dataframe[\"mean\"].values\n",
    "\n",
    "\n",
    "    # # MAIN PLOT\n",
    "    ax.plot(syllables, phonemes, 'o', lw = 2, ms = 8, zorder=2, alpha=1, color=\"darkblue\", label=language)\n",
    "    \n",
    "    x = syllables\n",
    "    y = phonemes\n",
    "    xlarge = np.arange(syllables[0], syllables[-1], 0.1)\n",
    "\n",
    "    # # POWER LAW EXPONENTIAL\n",
    "    popt, pcov = curve_fit(func_powerlawexp, syllables, phonemes)\n",
    "    expy = func_powerlawexp(xlarge, popt[0], popt[1], popt[2])\n",
    "    ax.plot(xlarge, expy, \"--\", lw=1.5, color=\"darkred\", alpha=0.9, label=\"fit to \" + r\"$y=\\alpha x^{\\beta}e^{-\\gamma}$\")\n",
    "\n",
    "    # # GET R2\n",
    "    residuals = y - func_powerlawexp(x, popt[0], popt[1], popt[2])\n",
    "    ss_res = np.sum(residuals**2)\n",
    "    ss_tot = np.sum((y - np.mean(y))**2)\n",
    "    R2 = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    parametros = [language + \" & \" + str(round(popt[0],2)) + \" & \" + latex_float(popt[1])+ \" & \" + latex_float(popt[2])+ \n",
    "                  \" & \" + str(round(R2,2))+ \" & \" + str(round(popt[1]/popt[2], 1)) + \"\\\\\" + \"\\\\\"]\n",
    "    \n",
    "    ax.plot(HMM.index, HMM.values, '-', lw = 4, ms = 1, zorder=2, alpha=0.6, color=\"gray\", label= \"BHMM\")\n",
    "\n",
    "    ax.legend(frameon = True, loc = \"upper right\", fontsize=10, ncol= 3)\n",
    "\n",
    "    ax.set_xticks([2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "    ax.set_yticks([1.8, 2.1, 2.4, 2.7, 3.0, 3.3])\n",
    "    ax.set_ylim([1.8,3.4])\n",
    "    ax.set_xlim([1.8, 12.2])\n",
    "    \n",
    "    if lang==\"it\" or lang==\"nl\" or lang==\"es\" or lang==\"pt\":\n",
    "        ax.set_xticks([2, 3, 4, 5, 6, 7, 8, 9])\n",
    "        ax.set_yticks([1.9, 2.2, 2.5, 2.8, 3.1])\n",
    "        ax.set_ylim([1.8,3.2])\n",
    "        ax.set_xlim([1.8, 9.2])\n",
    "    \n",
    "    if from1:\n",
    "        ax.set_xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
    "        ax.set_xlim([0.8, 11.2])\n",
    "        \n",
    "\n",
    "    ax.tick_params(axis='x', labelsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "    \n",
    "    ax.set_xlabel(r\"$Word$\" + \" \" + r\"$\\overline{size}$\" + \" \" + r\"($number$\" + \" \" + r\"$of$\" + \" \" + r\"$syllables)$\", fontsize=12)\n",
    "    ax.set_ylabel(r\"$Syllable$\" + \" \" + r\"$\\overline{size}$\" + \" \" + r\"$(characters)$\", fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    f.savefig(output_dir + outputname + \".pdf\", bbox_inches = 'tight', pad_inches = 0.1)\n",
    "    return(parametros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MAL full corpus starting from words with TWO syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "flag = 0\n",
    "parameterstosave = []\n",
    "\n",
    "for lang in listaidiomas:\n",
    "    flag +=1\n",
    "\n",
    "    f, ax = plt.subplots()\n",
    "    outputname = \"MAL_FullFrom2_\" + lang\n",
    "            \n",
    "    result_path = \"results/\" + lang + \"/menzerath_altmann_\" + lang + \".csv\"\n",
    "    df = pd.read_csv(result_path, index_col=0, header=[0,1]).mean_syllabe_length\n",
    "    df = df[df[\"count\"]>25]\n",
    "#     df = df[df.index.values<13] # At least some values FILTER\n",
    "    \n",
    "    BHMM_path = \"results/\" + lang + \"/HMM_menzerath_\" + lang + \".csv\"\n",
    "    BHMM = pd.read_csv(BHMM_path, index_col=1)[\"value\"]\n",
    "\n",
    "    output_dir = \"results/Figures_Article/FullCorpusFrom2/\"\n",
    "    df_withoutfirst = df[2::]\n",
    "    parameterstosave.append(plot_Menzerath(f, ax, outputname, flag, lang, df_withoutfirst, BHMM[1:int(df.index.values[-1])], output_dir))\n",
    "    \n",
    "pd.DataFrame(parameterstosave, columns=['Language & alpha & beta & gamma & R2']).to_csv(\"results/Figures_Article/FullCorpusFrom2/parametersFullCorpusFrom2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MAL full corpus starting from words with one syllable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameterstosave = []\n",
    "flag = 0\n",
    "for lang in listaidiomas:\n",
    "    flag +=1\n",
    "    f, ax = plt.subplots()\n",
    "    outputname = \"MAL_FullFrom1_\" + lang\n",
    "            \n",
    "    result_path = \"results/\" + lang + \"/menzerath_altmann_\" + lang + \".csv\"\n",
    "    df = pd.read_csv(result_path, index_col=0, header=[0,1]).mean_syllabe_length\n",
    "    df = df[df[\"count\"]>25] # At least some values FILTER\n",
    "#     df = df[df.index.values<12] # At least some values FILTER\n",
    "    \n",
    "    BHMM_path = \"results/\" + lang + \"/HMM_menzerath_\" + lang + \".csv\"\n",
    "    BHMM = pd.read_csv(BHMM_path, index_col=1)[\"value\"]\n",
    "\n",
    "    output_dir = \"results/Figures_Article/FullCorpusFrom1/\"\n",
    "    parameterstosave.append(plot_Menzerath(f, ax, outputname, flag, lang, df, BHMM[0:int(df.index.values[-1])], output_dir, from1=True))\n",
    "\n",
    "pd.DataFrame(parameterstosave, columns=['language & alpha & beta & gamma & R2 & beta/gamma']).to_csv(\"results/Figures_Article/FullCorpusFrom1/parametersFullCorpusFrom1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MAL full corpus vs averaging by books\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in listaidiomas:\n",
    "    output_dir = \"results/Figures_Article/Compare/\"\n",
    "    f, ax = plt.subplots()\n",
    "\n",
    "    # MAL AVERAGED BY BOOK\n",
    "    resultsAverage = \"results/\" + lang + \"/MALbyBook_\" + lang + \".csv\"\n",
    "    df = pd.read_csv(resultsAverage, header=None, sep = \" \")\n",
    "\n",
    "    # PLOT MAL FOR SOME BOOKS\n",
    "    for i in range(len(df)):\n",
    "        if i>500:\n",
    "            break\n",
    "        a = df.loc[i]\n",
    "        a.index+=1\n",
    "        a=a[a>0]\n",
    "        if i==0:\n",
    "            ax.plot(a.index.values[0], a.values[0], '-', lw = 1, ms = 1, zorder=0, alpha=1, color=\"gray\", label=\"MAL for each book\")\n",
    "        else:\n",
    "            ax.plot(a.index.values, a.values, '-', lw = 1, ms = 1, zorder=2, alpha=0.1, color=\"gray\")\n",
    "\n",
    "\n",
    "    # AVERAGE BY BOOK\n",
    "    lista_syllablesByBook = []\n",
    "    lista_meanvalueByBook = []\n",
    "    for i in range(11):\n",
    "        toconsider = df[i]\n",
    "        greaterthanzero = toconsider[toconsider>0]\n",
    "        if len(greaterthanzero)>1:\n",
    "            lista_syllablesByBook.append(i+1)\n",
    "            lista_meanvalueByBook.append(greaterthanzero.mean())\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # FULL DATA\n",
    "    resultFULL = \"results/\" + lang + \"/menzerath_altmann_\" + lang + \".csv\"\n",
    "    dfFULL = pd.read_csv(resultFULL, index_col=0, header=[0,1]).mean_syllabe_length\n",
    "    dfFULL = dfFULL[dfFULL[\"count\"]>25] # At least some values FILTER\n",
    "    dfFULL = dfFULL[dfFULL.index.values<12] # At least some values FILTER\n",
    "\n",
    "\n",
    "    # PLOT\n",
    "    if lang == \"fr\":\n",
    "        ax.plot(lista_syllablesByBook[0:len(dfFULL.index.values)-2], lista_meanvalueByBook[0:len(dfFULL.index.values)-2], \n",
    "                'o-', lw = 2, ms = 10, zorder=2, alpha=0.8, color=\"black\", label=\"MAL averaged by book\")\n",
    "        ax.plot(dfFULL.index.values[0:-2], dfFULL[\"mean\"].values[0:-2], \n",
    "                's-', lw = 2, ms = 10, zorder=2, alpha=0.8, color=\"darkblue\", label=\"MAL for full corpus\")\n",
    "    else:    \n",
    "        ax.plot(lista_syllablesByBook[0:len(dfFULL.index.values)-1], lista_meanvalueByBook[0:len(dfFULL.index.values)-1], \n",
    "                'o-', lw = 2, ms = 10, zorder=2, alpha=0.8, color=\"black\", label=\"MAL averaged by book\")\n",
    "        ax.plot(dfFULL.index.values[0:-1], dfFULL[\"mean\"].values[0:-1], \n",
    "                's-', lw = 2, ms = 10, zorder=2, alpha=0.8, color=\"darkblue\", label=\"MAL for full corpus\")\n",
    "\n",
    "    ax.set_xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "    ax.set_xlim([0.8, 10.2])\n",
    "    \n",
    "    if lang==\"de\":\n",
    "        ax.set_yticks([2.7, 3.0, 3.3])\n",
    "        ax.set_ylim([2.5,3.4])\n",
    "        \n",
    "    elif lang==\"en\":\n",
    "        ax.set_xticks([1, 2, 3, 4, 5, 6, 7])\n",
    "        ax.set_xlim([0.8, 7.2])\n",
    "        ax.set_ylim([2.1,3.2])\n",
    "        \n",
    "    elif lang==\"fr\":\n",
    "        ax.set_xticks([1, 2, 3, 4, 5, 6, 7])\n",
    "        ax.set_xlim([0.8, 7.2])\n",
    "        ax.set_ylim([2.3,2.9])\n",
    "\n",
    "    elif lang==\"fi\":\n",
    "        ax.set_xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "        ax.set_xlim([0.8, 10.2])\n",
    "        ax.set_ylim([2.4,2.85])\n",
    "        \n",
    "    ax.tick_params(axis='x', labelsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "    ax.set_xlabel(r\"$Word$\" + \" \" + r\"$\\overline{size}$\" + \" \" + r\"($number$\" + \" \" + r\"$of$\" + \" \" + r\"$syllables)$\", fontsize=12)\n",
    "    ax.set_ylabel(r\"$Syllable$\" + \" \" + r\"$\\overline{size}$\" + \" \" + r\"$(characters)$\", fontsize=12)\n",
    "\n",
    "    leg = ax.legend(frameon = True, loc = \"best\", fontsize=10, ncol= 1, title=return_language(lang))\n",
    "    leg.get_frame().set_linewidth(0.0)\n",
    "    leg.get_title().set_fontsize('13')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    f.savefig(output_dir + \"FullvsAverage_\" + lang + \".pdf\", bbox_inches = 'tight', pad_inches = 0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Clustersizes representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in listaidiomas:\n",
    "    output_dir = \"results/Figures_Article/ClusterSizes/\"\n",
    "    f, ax = plt.subplots()\n",
    "    n = 10\n",
    "    colors = plt.cm.gist_heat(np.linspace(0,1,n))\n",
    "\n",
    "    # MAL AVERAGED BY BOOK\n",
    "    resultsAverage = \"results/\" + lang + \"/clustersizes_\" + lang + \".csv\"\n",
    "    df = pd.read_csv(resultsAverage, header=None, sep = \",\", keep_default_na=True, skiprows=1, index_col=0).fillna(0)\n",
    "\n",
    "    lista_syllables = []\n",
    "    minimoy = 5\n",
    "    maximoy = 0\n",
    "    for i in range(1,8):\n",
    "        lista_syllables.append(i)\n",
    "        if sum(df.loc[i+2]>0)<1: break\n",
    "        if sum(df.loc[i+1]>0)<1: break\n",
    "        if lang==\"is\" and i>6: break\n",
    "        clusters_n = df.loc[i]\n",
    "        clusters_n = clusters_n[clusters_n>0].values\n",
    "        \n",
    "        if i == 1:\n",
    "            ax.plot(0.5, clusters_n, 'o-', c=colors[i], ms=8, lw=3, alpha=0.9, label=str(i) + \" syll.\")\n",
    "        else:\n",
    "            if min(clusters_n)<minimoy: minimoy=min(clusters_n)\n",
    "            if max(clusters_n)>maximoy: maximoy=max(clusters_n)\n",
    "            array = np.asarray(lista_syllables)\n",
    "            clustersizes = (array-min(array))/(max(array) - min(array))\n",
    "            ax.plot(clustersizes, clusters_n, 'o-', c=colors[i], ms=8, lw=2, alpha=0.8, label=str(i) + \" syll.\")\n",
    "\n",
    "    ax.set_xticks([0, 0.5, 1])\n",
    "    ax.set_xlim([-0.03, 1.03])\n",
    "    ax.set_ylim([minimoy-0.2, maximoy+0.05])\n",
    "\n",
    "    ax.tick_params(axis='x', labelsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "    ax.set_xlabel(r\"$Adimensional$\" + \" \" + r\"$word$\" + \" \" + r\"$size$\", fontsize=12)\n",
    "    ax.set_ylabel(r\"$Cluster$\" + \" \" + r\"$\\overline{size}$\" + \" \" + r\"$(characters)$\", fontsize=12)\n",
    "\n",
    "    leg = ax.legend(frameon = False, loc = 4, fontsize=10, ncol= 4, title=return_language(lang))\n",
    "    leg.get_title().set_fontsize('12')\n",
    "    f.savefig(output_dir + \"Clustersizes_\" + lang + \".pdf\", bbox_inches = 'tight', pad_inches = 0.1)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
